{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e23ecb-fa3f-4eaf-a604-6e75b4b848fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fbbe0c6-2997-41e1-ae62-893d9a39fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.path.dirname(os.path.abspath(\"Data_Cleaning.ipynb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1bcd9a-2ab3-4d06-837c-10bc1238f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fucntion to Clean tweet data\n",
    "def Clean(text):\n",
    "    #lowercase for every word\n",
    "    text = text.lower()\n",
    "\n",
    "    #Clean Pattern\n",
    "    #remove USER\n",
    "    text = re.sub(r'user', ' ', text)\n",
    "    #remove 'RT'\n",
    "    text = re.sub(r'rt', ' ', text)\n",
    "    #remove 'URL'\n",
    "    text = re.sub(r'url', ' ', text)\n",
    "    #remove HTTPS\n",
    "    text = re.sub(r'https', ' ', text)\n",
    "    #remove HTTP\n",
    "    text = re.sub(r'http', ' ', text)\n",
    "    #remove &amp\n",
    "    text = re.sub(r'&amp', ' ', text)\n",
    "\n",
    "    #Clean_Unnecessary_Character\n",
    "    #remove \\n or every word afte '\\' with space\n",
    "    text = re.sub(r'\\\\+[a-zA-Z0-9]+', ' ', text)\n",
    "    #remove text emoji\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]{2,}|:[a-zA-Z0-9]{0,}', ' ', text)\n",
    "    #remove all unnecessary character \n",
    "    text = re.sub(r'[^0-9a-zA-Z\\s]+', ' ', text)\n",
    "    #remove all number\n",
    "    text = re.sub(r'[0-9]+', ' ', text)\n",
    "    #remove extra space\n",
    "    text = re.sub(r'  +', ' ', text)\n",
    "    #remove space at the start or the end of string\n",
    "    text = re.sub(r'^ +| +$', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "#tokenization Function\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "#import file new_kamusalay.csv\n",
    "kamus_alay = pd.read_csv(r\"E:\\BINAR\\Binar-Gold-Challenge\\Dataset\\new_kamusalay.csv\", \n",
    "                         encoding = 'ISO-8859-1', header = None)\n",
    "kamus_alay = kamus_alay.rename(columns={0: 'kata alay', 1: 'arti kata'})\n",
    "\n",
    "#Create dictionary from kamus_alay\n",
    "kamus_alay_dict = dict(zip(kamus_alay['kata alay'], kamus_alay['arti kata']))\n",
    "\n",
    "#normalization function to convert every word tha contain 'kata alay' to 'arti kata'\n",
    "def normalization(text):\n",
    "    newlist = []\n",
    "    for word in text:\n",
    "        if word in kamus_alay_dict:\n",
    "            text = kamus_alay_dict[word]\n",
    "            newlist.append(text)\n",
    "        else:\n",
    "            text = word\n",
    "            newlist.append(text)\n",
    "    return newlist\n",
    "\n",
    "#remove stopwords\n",
    "\n",
    "#list stopword from NLTK\n",
    "stopword_list = ['yang', 'untuk', 'pada', 'ke', 'para', 'namun', 'menurut', 'antara', \n",
    "                 'dia', 'dua', 'ia','ia', 'seperti', 'jika', 'sehingga', 'kembali', 'dan', \n",
    "                 'ini', 'karena', 'kepada', 'oleh', 'saat', 'sementara', 'setelah', 'kami', \n",
    "                 'sekitar', 'bagi', 'serta', 'di', 'dari', 'telah', 'sebagai', 'masih', 'hal', \n",
    "                 'ketika', 'adalah', 'itu', 'dalam', 'bahwa', 'atau', 'kita', 'dengan', 'akan', \n",
    "                 'juga', 'ada', 'mereka', 'sudah', 'saya', 'terhadap', 'secara', 'agar', 'lain', \n",
    "                 'anda', 'begitu', 'mengapa', 'kenapa', 'yaitu', 'yakni', 'daripada', 'itulah', \n",
    "                 'lagi', 'maka', 'tentang', 'demi', 'dimana', 'kemana', 'pula', 'sambil', 'sebelum', \n",
    "                 'sesudah', 'supaya', 'guna', 'kah', 'pun', 'sampai', 'sedangkan', 'selagi', 'sementara', \n",
    "                 'tetapi', 'apakah', 'kecuali', 'sebab', 'seolah', 'seraya', 'seterusnya', 'dsb', 'dst', \n",
    "                 'dll', 'dahulu', 'dulunya', 'anu', 'demikian', 'mari', 'nanti', 'oh', 'ok', 'setiap', \n",
    "                 'sesuatu','saja', 'toh', 'walau', 'amat', 'apalagi', 'dengan', 'bahwa', 'oleh']\n",
    "\n",
    "stopword_list.extend([\"yg\", \"dg\", \"rt\", \"dgn\", \"ny\", \"d\", 'klo',\n",
    "                       'kalo', 'amp', 'biar', 'bikin', 'bilang',\n",
    "                       'gak', 'ga', 'krn', 'nya', 'nih', 'sih',\n",
    "                       'si', 'tau', 'tdk', 'tuh', 'utk', 'ya',\n",
    "                       'jd', 'jgn', 'sdh', 'aja', 'n', 't',\n",
    "                       'nyg', 'hehe', 'pen', 'u', 'nan', 'loh', 'rt',\n",
    "                       'gue', 'yah', 'kayak'])\n",
    "\n",
    "stopword_list = set(stopword_list)\n",
    "\n",
    "#remove stopword function\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword_list]\n",
    "    return text\n",
    "\n",
    "#Find NUll 'String' Value \n",
    "def clean_non_existed(text):\n",
    "    if text == '':\n",
    "        return None\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "#function to run all the function\n",
    "def clean_data(text):\n",
    "    text = Clean(text)\n",
    "    text = tokenization(text)\n",
    "    text = normalization(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = ' '.join(text)\n",
    "    text = clean_non_existed(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73425f64-8745-4b4c-981f-8d88de8dcc90",
   "metadata": {},
   "source": [
    "# Data Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b05789-eadc-4c71-8789-36cca816624a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
       "2  lokasi strategis di jalan sumatera bandung . t...  positive\n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  positive\n",
       "4  duh . jadi mahasiswa jangan sombong dong . kas...  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_table(current_directory + \"\\\\Dataset\\\\train_preprocess.tsv.txt\", sep='\\t', header=None)\n",
    "df_train = df_train.rename(columns={0: 'text', 1: 'label'})\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee563e1-9c74-4ab6-b572-4b9358ec5ac5",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff82b7bf-6104-4436-addc-c5ce608a5ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>warung dimiliki pengusaha pabrik tahu puluhan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mohon ulama lurus k mmbri hujjah pak ai apa ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lokasi strategis jalan sumatra bandung tempat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "      <td>betapa bahagia diri unboxing paket barang bagu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "      <td>aduh jadi mahasiswa jangan sombong dong kasih ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  \\\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  positive   \n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral   \n",
       "2  lokasi strategis di jalan sumatera bandung . t...  positive   \n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  positive   \n",
       "4  duh . jadi mahasiswa jangan sombong dong . kas...  negative   \n",
       "\n",
       "                                          text_clean  \n",
       "0  warung dimiliki pengusaha pabrik tahu puluhan ...  \n",
       "1  mohon ulama lurus k mmbri hujjah pak ai apa ha...  \n",
       "2  lokasi strategis jalan sumatra bandung tempat ...  \n",
       "3  betapa bahagia diri unboxing paket barang bagu...  \n",
       "4  aduh jadi mahasiswa jangan sombong dong kasih ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text_clean'] = df_train.text.apply(clean_data)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4144d38b-6dd1-4fe5-a148-a777bf3e7031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "positive    6416\n",
       "negative    3436\n",
       "neutral     1148\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bce5d4f-ae12-4058-b143-b702230a4713",
   "metadata": {},
   "source": [
    "## Drop Duplicated & Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c758ae2d-db2e-4f21-9b04-9f2ad4984a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.drop_duplicates(subset='text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b83ce9db-2ebe-4bf0-8ac3-fe899d2262ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "positive    6383\n",
       "negative    3412\n",
       "neutral     1138\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60e89d-67b8-4414-813d-3d0c149bfc68",
   "metadata": {},
   "source": [
    "## Saving Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed483389-a5fa-47f6-bb42-7ec2473888e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"Clean_train_preprocess.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec29ca-f55f-4367-b286-0c389ed4bfa9",
   "metadata": {},
   "source": [
    "# Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7145eeb-2ffe-484e-9a8c-482bf07df598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>Abusive</th>\n",
       "      <th>HS_Individual</th>\n",
       "      <th>HS_Group</th>\n",
       "      <th>HS_Religion</th>\n",
       "      <th>HS_Race</th>\n",
       "      <th>HS_Physical</th>\n",
       "      <th>HS_Gender</th>\n",
       "      <th>HS_Other</th>\n",
       "      <th>HS_Weak</th>\n",
       "      <th>HS_Moderate</th>\n",
       "      <th>HS_Strong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- disaat semua cowok berusaha melacak perhatia...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT USER: USER siapa yang telat ngasih tau elu?...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41. Kadang aku berfikir, kenapa aku tetap perc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER USER Kaum cebong kapir udah keliatan dong...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  HS  Abusive  \\\n",
       "0  - disaat semua cowok berusaha melacak perhatia...   1        1   \n",
       "1  RT USER: USER siapa yang telat ngasih tau elu?...   0        1   \n",
       "2  41. Kadang aku berfikir, kenapa aku tetap perc...   0        0   \n",
       "3  USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...   0        0   \n",
       "4  USER USER Kaum cebong kapir udah keliatan dong...   1        1   \n",
       "\n",
       "   HS_Individual  HS_Group  HS_Religion  HS_Race  HS_Physical  HS_Gender  \\\n",
       "0              1         0            0        0            0          0   \n",
       "1              0         0            0        0            0          0   \n",
       "2              0         0            0        0            0          0   \n",
       "3              0         0            0        0            0          0   \n",
       "4              0         1            1        0            0          0   \n",
       "\n",
       "   HS_Other  HS_Weak  HS_Moderate  HS_Strong  \n",
       "0         1        1            0          0  \n",
       "1         0        0            0          0  \n",
       "2         0        0            0          0  \n",
       "3         0        0            0          0  \n",
       "4         0        0            1          0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet= pd.read_csv(current_directory + \"\\Dataset\\data.csv\", encoding='ISO-8859-1')\n",
    "df_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3dcdf-ba3d-4589-be48-af50b472b2fc",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b00db723-1970-4ab8-85cf-d1684c0fabd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>Abusive</th>\n",
       "      <th>HS_Individual</th>\n",
       "      <th>HS_Group</th>\n",
       "      <th>HS_Religion</th>\n",
       "      <th>HS_Race</th>\n",
       "      <th>HS_Physical</th>\n",
       "      <th>HS_Gender</th>\n",
       "      <th>HS_Other</th>\n",
       "      <th>HS_Weak</th>\n",
       "      <th>HS_Moderate</th>\n",
       "      <th>HS_Strong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>di saat semua cowok berusaha melacak perhatian...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>siapa telat memberi kamu edan sarap bergaul ci...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kadang aku berpikir aku tetap percaya tuhan pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aku aku matamu sipit tapi dilihat mana aku</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kaum cebong kafir kelihatan dongoknya awal tam...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  HS  Abusive  \\\n",
       "0  di saat semua cowok berusaha melacak perhatian...   1        1   \n",
       "1  siapa telat memberi kamu edan sarap bergaul ci...   0        1   \n",
       "2  kadang aku berpikir aku tetap percaya tuhan pa...   0        0   \n",
       "3         aku aku matamu sipit tapi dilihat mana aku   0        0   \n",
       "4  kaum cebong kafir kelihatan dongoknya awal tam...   1        1   \n",
       "\n",
       "   HS_Individual  HS_Group  HS_Religion  HS_Race  HS_Physical  HS_Gender  \\\n",
       "0              1         0            0        0            0          0   \n",
       "1              0         0            0        0            0          0   \n",
       "2              0         0            0        0            0          0   \n",
       "3              0         0            0        0            0          0   \n",
       "4              0         1            1        0            0          0   \n",
       "\n",
       "   HS_Other  HS_Weak  HS_Moderate  HS_Strong  \n",
       "0         1        1            0          0  \n",
       "1         0        0            0          0  \n",
       "2         0        0            0          0  \n",
       "3         0        0            0          0  \n",
       "4         0        0            1          0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet['Tweet'] = df_tweet.Tweet.apply(clean_data)\n",
    "df_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a89b58-a5f9-4931-ae58-9334c1e6d1b7",
   "metadata": {},
   "source": [
    "## Drop Duplicated & Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd06e7e5-63ff-4bc0-abfa-3d18291dd7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13169, 13)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7baa3962-7c76-4540-9ff7-65db171a3a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet = df.dropna()\n",
    "df_tweet = df.drop_duplicates(subset='Tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b5daa5e-1567-4e34-a149-08c67977112e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12833, 13)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e068c21-402e-4cb2-91bf-eb40a1655ba1",
   "metadata": {},
   "source": [
    "## Saving Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7c8bc6f-d75b-44d7-a66c-37ab4ff34675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.to_csv(\"Clean_data_Tweet.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
